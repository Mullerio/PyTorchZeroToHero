{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization and Loss functions in PyTorch\n",
    "\n",
    "Before diving into Neural Networks, we first investigate how the Model Optimization works. For that, PyTorch offers `torch.optim`.\n",
    "\n",
    "In `torch.optim` we have a base class called `torch.optim.Optimizer` from which all Optimizers inherit. Using this class, we can also implement our own Optimization Algorithms, however, PyTorch also offers a plethora of already implement Algorithms, a list can be found here https://pytorch.org/docs/stable/optim.html.\n",
    "\n",
    "For loss functions, PyTorch offers `torch.nn`, which is the fundamental building block for its Autograd graph, the loss functions come from `torch.nn.Module` from which all parts of our Neural Network, including the loss functions, inherit. We also can write custom loss functions using `torch.autograd.Function`.\n",
    "\n",
    "In `Toy Optimization` we saw some basic examples how this looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Optimization Algorithms and Loss functions in PyTorch\n",
    "\n",
    "Through torch.optim and torch.nn we can implement our Own loss functions and optimization Algorithms. \n",
    "\n",
    "This can be useful if we want to play around with our own loss functions or optiization algorithms, or if we want to modify existing ones. \n",
    "\n",
    "For the Optimizer, we need to implement the functions __init__() for initilization and step() which takes a optimization step.\n",
    "\n",
    "For the loss function, what we need to implement, aside from __init__(), depends on wether or not we used `torch.autograd.Function` (forward and backward) as our class to inherit from or `torch.nn.Module`, the latter (i think) is more common, as here we only need to implement the forward method, since the backward is done automatically via the autograd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us see how custom optimization Algorithms look like in PyTorch\n",
    "class customOptimization(optim.Optimizer):\n",
    "    def __init__(self, params, lr = 0.01):\n",
    "        super().__init__(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us see how custom loss functions look like in PyTorch\n",
    "\n",
    "class customloss(nn.Module):\n",
    "    def __init__():\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
