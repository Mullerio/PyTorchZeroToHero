{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization and Loss functions in PyTorch\n",
    "\n",
    "Before diving into Neural Networks, we first investigate how the Model Optimization works. For that, PyTorch offers `torch.optim`.\n",
    "\n",
    "In `torch.optim` we have a base class called `torch.optim.Optimizer` from which all Optimizers inherit. Using this class, we can also implement our own Optimization Algorithms, however, PyTorch also offers a plethora of already implement Algorithms, a list can be found here https://pytorch.org/docs/stable/optim.html.\n",
    "\n",
    "For loss functions, PyTorch offers `torch.nn`, which is the fundamental building block for its Autograd graph, the loss functions come from `torch.nn.Module` from which all parts of our Neural Network, including the loss functions, inherit. We also can write custom loss functions using `torch.autograd.Function`.\n",
    "\n",
    "In `Toy Optimization` we saw some basic examples how this looks like. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Optimization Algorithms and Loss functions in PyTorch\n",
    "\n",
    "Through torch.optim and torch.nn we can implement our Own loss functions and optimization Algorithms. \n",
    "\n",
    "This can be useful if we want to play around with our own loss functions or optiization algorithms, or if we want to modify existing ones. \n",
    "\n",
    "For the Optimizer, we need to implement the functions __init__() for initilization and step() which takes a optimization step.\n",
    "\n",
    "For the loss function, what we need to implement, aside from __init__(), depends on wether or not we used `torch.autograd.Function` (forward and backward) as our class to inherit from or `torch.nn.Module`, the latter (i think) is more common, as here we only need to implement the forward method, since the backward is done automatically via the autograd. When using `torch.autograd.Function` we implement a new function which we can use autograd on, which essentially is what the training Algorithm does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom AdamW Algorithm \n",
    "\n",
    "Below we give an example of a custom implementation for optimizers in PyTorch. It is inspired by the PyTorch docs https://pytorch.org/docs/stable/generated/torch.optim.AdamW.html - there, many more considerations are made, which, for the sake of simplicity, we are not doing here. \n",
    "\n",
    "Here, `params` is a Iterable of all the things (i.e. weights, bias etc.) we want to optimize over.\n",
    "\n",
    "Through the Framework of the Optimizer class from which we inheret, we can actually also define different parameters, like learning rates or decay, for different kind of parameters (imagine, you want to learn the weights of one layer faster than the weights in another etc) \n",
    "\n",
    "This we can do through the different groups, by passing `defaults` to the Optimizer class, we ensure that all parameters are accessible in the group dictionary, even if not all where specified for that group.\n",
    "\n",
    "Here, in the step, all information relevant to the optimization in the `state` dictionary. We also allow `maxamize` - this allows the user to utilize this version of AdamW for maximizing instead of minimizing. Which might be useful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us see how custom optimization Algorithms look like in PyTorch\n",
    "class customAdamW(optim.Optimizer):\n",
    "    def __init__(\n",
    "        self, params, lr = 0.01, beta1 = 0.9, beta2 = 0.999, eps = 1e-7, decay = 0.0, maximize = False):\n",
    "        defaults = dict(lr = 0.01, beta1 = 0.9, beta2 = 0.999, eps = 1e-7, decay = 0.0, maximize = False)\n",
    "        super().__init__(params,defaults)\n",
    "        \n",
    "    def step(self):\n",
    "        for group in self.param_groups:\n",
    "            for p in group[\"params\"]:\n",
    "                #check if gradient has been calculated already\n",
    "                if p.grad is None: \n",
    "                    continue\n",
    "                \n",
    "                gradient = p.grad.data\n",
    "                \n",
    "                if group[\"maximize\"]: \n",
    "                    gradient = -gradient\n",
    "                \n",
    "                \n",
    "                state = self.state[p] # get the state of the current parameter\n",
    "                \n",
    "                # get our parameters \n",
    "                eps = group[\"eps\"]\n",
    "                a = group[\"lr\"]\n",
    "                weight_decay = group[\"decay\"]\n",
    "                beta1 = group[\"beta1\"]\n",
    "                beta2 = group[\"beta2\"]\n",
    "                #init the state if we are in the first iteration\n",
    "                if \"state\" not in state:\n",
    "                    state[\"step\"] = 0\n",
    "                    #init the moments\n",
    "                    state[\"moment1\"] = torch.zeros_like(p.data)\n",
    "                    state[\"moment2\"] = torch.zeros_like(p.data)\n",
    "                \n",
    "                # regulraization\n",
    "                p.data = p.data - a* weight_decay * p.data\n",
    "                \n",
    "                state[\"step\"] += 1\n",
    "                state[\"moment1\"] = state[\"moment1\"] * beta1 + (1-beta1) *gradient\n",
    "                state[\"moment2\"] = state[\"moment2\"] * beta2 + (1-beta2) * gradient*gradient\n",
    "                \n",
    "                bias1_correction = state[\"moment1\"]/(1 - beta1 ** state[\"step\"])\n",
    "                bias2_correction = state[\"moment2\"]/(1-beta2 ** state[\"step\"])\n",
    "                \n",
    "                p.data = p.data - a *bias1_correction/(torch.sqrt(bias2_correction) + eps)\n",
    "        \n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.2771, -0.4816,  0.2808],\n",
      "        [-0.4333,  0.0365,  0.5661]], requires_grad=True) Parameter containing:\n",
      "tensor([-0.5408, -0.3892], requires_grad=True)\n",
      "Before Training we have: tensor([-0.4608,  0.7794], grad_fn=<ViewBackward0>)\n",
      "After Training we have: tensor([ 0.0192, -0.0206], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Lets see how our Optimizer works on the Optimization from ToyOptimization\n",
    "n = 3\n",
    "m = 2\n",
    "toy_model = nn.Linear(n,m) \n",
    "W = toy_model.weight\n",
    "b = toy_model.bias\n",
    "inputs = torch.arange(n, dtype=torch.float32)\n",
    "labels = torch.zeros(m)\n",
    "print(f\"Before Training we have: {toy_model(inputs)}\")\n",
    "lossfunction = nn.MSELoss()\n",
    "toy_optimizer = customAdamW(toy_model.parameters(), lr=0.01)\n",
    "for i in range(100):\n",
    "    toy_optimizer.zero_grad()\n",
    "    output = toy_model(inputs)\n",
    "    loss = lossfunction(labels,output)\n",
    "    loss.backward()\n",
    "    toy_optimizer.step()\n",
    "    \n",
    "print(f\"After Training we have: {toy_model(inputs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It works :) \n",
    "\n",
    "Now, lets see how we can implement our own loss functions. Here we are going to inherit from the `nn.Module` and we are just doing the classic MSE loss with regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training we have: tensor([-1.4156,  0.3178], grad_fn=<ViewBackward0>)\n",
      "After Training we have: tensor([ 0.0244, -0.0023], grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Let us see how custom loss functions look like in PyTorch\n",
    "\n",
    "class RegularizedMSELoss(nn.Module):\n",
    "    def __init__(self, lambd = 0.01):\n",
    "        super().__init__()\n",
    "        self.lambd = lambd\n",
    "        \n",
    "    def forward(self, inputs,labels):\n",
    "        loss = torch.mean((inputs-labels)**2) + self.lambd * torch.norm(inputs, p = 2)\n",
    "        return loss\n",
    "    \n",
    "# Lets see how our Optimizer combined with the above loss functions works on the Optimization from ToyOptimization\n",
    "n = 3\n",
    "m = 2\n",
    "toy_model = nn.Linear(n,m) \n",
    "W = toy_model.weight\n",
    "b = toy_model.bias\n",
    "inputs = torch.arange(n, dtype=torch.float32)\n",
    "labels = torch.zeros(m)\n",
    "print(f\"Before Training we have: {toy_model(inputs)}\")\n",
    "lossfunction = RegularizedMSELoss(lambd = 0.001)\n",
    "toy_optimizer = customAdamW(toy_model.parameters(), lr=0.01)\n",
    "for i in range(100):\n",
    "    toy_optimizer.zero_grad()\n",
    "    output = toy_model(inputs)\n",
    "    loss = lossfunction(labels,output)\n",
    "    loss.backward()\n",
    "    toy_optimizer.step()\n",
    "    \n",
    "print(f\"After Training we have: {toy_model(inputs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
